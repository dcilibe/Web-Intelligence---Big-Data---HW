{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf360
{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red49\green49\blue49;\red255\green255\blue255;\red16\green76\blue214;
}
\paperw11900\paperh16840\margl1440\margr1440\vieww9000\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sl720\ql\qnatural

\f0\b\fs36 \cf2 \cb3 Homework 3 (Programming Assignment)\
\pard\pardeftab720\sl360\sa180\ql\qnatural

\b0\fs26 \cf2 Download data files bundled as a .zip file from {\field{\*\fldinst{HYPERLINK "http://spark-public.s3.amazonaws.com/bigdata/Assignment%20Data/hw3data.zip"}}{\fldrslt \cf4 hw3data.zip}}\
Each file in this archive contains entries that look like:\
journals/cl/SantoNR90:::Michele Di Santo::Libero Nigro::Wilma Russo:::Programmer-Defined Control Abstractions in Modula-2.\
that represent bibliographic information about publications, formatted as follows:\
paper-id:::author1::author2::\'85. ::authorN:::title\
\pard\pardeftab720\sl360\sa180\ql\qnatural

\b \cf2 Your task is to compute how many times every term occurs across titles, for 
\i each
\i0  author.
\b0 \
For example, the author Alberto Pettorossi the following terms occur in titles with the indicated cumulative frequencies (across all his papers): program:3, transformation:2, transforming:2, using:2, programs:2, and logic:2.\
Remember that an author might have written multiple papers, which might be listed in multiple files. Further notice that \'91terms\'92 must exclude common stop-words, such as prepositions etc. For the purpose of this assignment, the stop-words that need to be omitted are listed in the script{\field{\*\fldinst{HYPERLINK "http://spark-public.s3.amazonaws.com/bigdata/Assignment%20Data/stopwords.py"}}{\fldrslt \cf4 stopwords.py}}. In addition, single letter words, such as "a" can be ignored; also hyphens can be ignored (i.e. deleted). Lastly, periods, commas, etc. need to be ignored; in other words, only alphabets and numbers can be part of a title term: Thus, \'93program\'94 and \'93program.\'94 should both be counted as the term \'91program\'92, and "map-reduce" should be taken as 'map reduce'. Note: You do 
\i not
\i0  need to do stemming, i.e. "algorithm" and "algorithms" can be treated as separate terms.\
The assignment is to write a parallel map-reduce program for the above task using octo.py, which is a lightweight map-reduce implementation written in Python available from {\field{\*\fldinst{HYPERLINK "http://code.google.com/p/octopy/"}}{\fldrslt \cf4 http://code.google.com/p/octopy/}}.\
Once you have computed the output, i.e. the terms-frequencies per author, go attempt Homework 3 where you will be asked questions that can be simply answered using your computed output, such as the top terms that occur for some particular author.\
Note: There is no need to submit the code; I assume you will experiment using octo.py to learn how to program using map-reduce. Of course, you can always write a serial program for the task at hand, but then you won\'92t learn anything about map-reduce.\
Lastly, please note that octo.py is a rather inefficient implementation of map-reduce. Some of you might want to delve into the code to figure out exactly why. At the same time, this inefficiency is likely to amplify any errors you make in formulating the map and reduce functions for the task at hand. So if your code starts taking too long, say more than an hour to run, there is probably something wrong.\
}